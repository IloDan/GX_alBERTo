ClearML Task: created new task id=90b009a327b1477488b3b943f8f611c7
======> WARNING! Git diff too large to store (578kb), skipping uncommitted changes <======
ClearML results page: https://app.clear.ml/projects/364457bc04234a8b80e439e974b93968/experiments/90b009a327b1477488b3b943f8f611c7/output/log
leftpos: 32767
rightpos: 98303
maxlen: 65536
batch_size:  32
which_dataset:  2
label:  fpkm_uq_median
Dimensioni dataset di test:`618`
Dimensioni dataset di validazione:`683`
Dimensioni dataset di train:`16849`
Loss on train for epoch 1: 0.9723354012509224
lr:  [5.0047483380816714e-05]
Loss on validation for epoch 1: 0.960888537493619
Loss on train for epoch 2: 0.8868002427257669
lr:  [0.00010009496676163343]
Loss on validation for epoch 2: 1.038169503211975
Loss on train for epoch 3: 0.8570566161533913
lr:  [0.00015014245014245014]
Loss on validation for epoch 3: 0.8214694830504331
Loss on train for epoch 4: 0.8422641878562362
lr:  [0.00020018993352326686]
Loss on validation for epoch 4: 0.7739030041477897
Loss on train for epoch 5: 0.8394744367368759
lr:  [0.00025023741690408357]
Loss on validation for epoch 5: 3.5761293172836304
Loss on train for epoch 6: 0.8372663264030298
lr:  [0.0003002849002849003]
Loss on validation for epoch 6: 0.7481289194388823
Loss on train for epoch 7: 0.8310915599285539
lr:  [0.000350332383665717]
Loss on validation for epoch 7: 1.4259816950017756
Loss on train for epoch 8: 0.8299908638565997
lr:  [0.0004003798670465337]
Loss on validation for epoch 8: 0.928971913727847
Loss on train for epoch 9: 0.8372185947886002
lr:  [0.00045042735042735043]
Loss on validation for epoch 9: 1.0255485353144733
Loss on train for epoch 10: 0.8652896097308092
lr:  [0.0004999472963002003]
Loss on validation for epoch 10: 1.8730367747220127
Model saved at epoch 10
Loss on train for epoch 11: 0.8575403645097418
lr:  [0.0004943923263413092]
Loss on validation for epoch 11: 1.3234387229789386
Loss on train for epoch 12: 0.8452587502052481
lr:  [0.000488837356382418]
Loss on validation for epoch 12: 2.5528651801022617
Loss on train for epoch 13: 0.8384849053067094
lr:  [0.00048328238642352694]
Loss on validation for epoch 13: 1.8424937995997341
Loss on train for epoch 14: 0.8272769440962197
lr:  [0.0004777274164646358]
Loss on validation for epoch 14: 1.665023085745898
Loss on train for epoch 15: 0.8352068412122962
lr:  [0.0004721724465057447]
Loss on validation for epoch 15: 0.8505088754675605
Loss on train for epoch 16: 0.8294761077389545
lr:  [0.0004666174765468536]
Loss on validation for epoch 16: 1.0675969394770535
Loss on train for epoch 17: 0.8260698509623475
lr:  [0.0004610625065879625]
Loss on validation for epoch 17: 0.8083677833730524
Loss on train for epoch 18: 0.8268614493918374
lr:  [0.0004555075366290713]
Loss on validation for epoch 18: 2.196262841874903
Loss on train for epoch 19: 0.8224994201474669
lr:  [0.0004499525666701802]
Loss on validation for epoch 19: 0.9001778526739641
Loss on train for epoch 20: 0.8135259037225929
lr:  [0.0004443975967112892]
Loss on validation for epoch 20: 0.9465838643637571
Model saved at epoch 20
Loss on train for epoch 21: 0.817562504556645
lr:  [0.000438842626752398]
Loss on validation for epoch 21: 0.7750907486135309
Loss on train for epoch 22: 0.8050716519355774
lr:  [0.0004332876567935069]
Loss on validation for epoch 22: 1.1832756115631624
Loss on train for epoch 23: 0.7996435213473535
lr:  [0.0004277326868346158]
Loss on validation for epoch 23: 0.7644566690379923
Loss on train for epoch 24: 0.8042639479239028
lr:  [0.0004221777168757247]
Loss on validation for epoch 24: 0.6905686096711592
Loss on train for epoch 25: 0.7984305599835159
lr:  [0.00041662274691683357]
Loss on validation for epoch 25: 0.7574164406819777
Loss on train for epoch 26: 0.7899445950193242
lr:  [0.00041106777695794247]
Loss on validation for epoch 26: 4.3153216730464585
Loss on train for epoch 27: 0.7922549206459545
lr:  [0.00040551280699905137]
Loss on validation for epoch 27: 0.8371072005141865
Loss on train for epoch 28: 0.7847364551089068
lr:  [0.00039995783704016027]
Loss on validation for epoch 28: 0.7906407172029669
Loss on train for epoch 29: 0.7841992831207544
lr:  [0.0003944028670812691]
Loss on validation for epoch 29: 0.8000639541582628
Loss on train for epoch 30: 0.7735739189714363
lr:  [0.000388847897122378]
Loss on validation for epoch 30: 0.8351173427971926
Model saved at epoch 30
Loss on train for epoch 31: 0.7742874420458271
lr:  [0.0003832929271634869]
Loss on validation for epoch 31: 0.8025130480527878
Loss on train for epoch 32: 0.7737702116568129
lr:  [0.00037773795720459576]
Loss on validation for epoch 32: 1.1902307028120214
Loss on train for epoch 33: 0.7679337921925242
lr:  [0.00037218298724570466]
Loss on validation for epoch 33: 0.8323188735680147
Loss on train for epoch 34: 0.7689570742155615
lr:  [0.00036662801728681356]
Loss on validation for epoch 34: 1.1856332150372593
Loss on train for epoch 35: 0.7645213618676622
lr:  [0.00036107304732792246]
Loss on validation for epoch 35: 0.7148866653442383
Loss on train for epoch 36: 0.7633722228558285
lr:  [0.0003555180773690313]
Loss on validation for epoch 36: 0.7253479591824792
Loss on train for epoch 37: 0.7576883976441406
lr:  [0.0003499631074101402]
Loss on validation for epoch 37: 0.8235110410235145
Loss on train for epoch 38: 0.7549316779033509
lr:  [0.0003444081374512491]
Loss on validation for epoch 38: 0.6536994766105305
Loss on train for epoch 39: 0.7545034802842185
lr:  [0.00033885316749235794]
Loss on validation for epoch 39: 0.7266545268622312
Loss on train for epoch 40: 0.7507278038157005
lr:  [0.00033329819753346684]
Loss on validation for epoch 40: 0.7317080159078945
Model saved at epoch 40
Loss on train for epoch 41: 0.7435473979537356
lr:  [0.00032774322757457574]
Loss on validation for epoch 41: 0.7369630431587045
Loss on train for epoch 42: 0.7496115013928748
lr:  [0.00032218825761568464]
Loss on validation for epoch 42: 0.7266231070865284
Loss on train for epoch 43: 0.7537595476439148
lr:  [0.0003166332876567935]
Loss on validation for epoch 43: 0.8590100570158525
Loss on train for epoch 44: 0.7471054520394363
lr:  [0.0003110783176979024]
Loss on validation for epoch 44: 0.7656996846199036
Loss on train for epoch 45: 0.7485086845492049
lr:  [0.0003055233477390113]
Loss on validation for epoch 45: 0.9966359314593402
Loss on train for epoch 46: 0.7472609611797152
lr:  [0.00029996837778012013]
Loss on validation for epoch 46: 0.7836874642155387
Loss on train for epoch 47: 0.7409810252501797
lr:  [0.00029441340782122903]
Loss on validation for epoch 47: 0.8705467514016412
Loss on train for epoch 48: 0.7376014312032957
lr:  [0.00028885843786233793]
Loss on validation for epoch 48: 0.8228525045243177
Loss on train for epoch 49: 0.7338083169265761
lr:  [0.00028330346790344683]
Loss on validation for epoch 49: 1.0410334169864655
Loss on train for epoch 50: 0.7404844754108668
lr:  [0.0002777484979445557]
Loss on validation for epoch 50: 0.6497720750895414
Model saved at epoch 50
Loss on train for epoch 51: 0.7365274256275546
lr:  [0.0002721935279856646]
Loss on validation for epoch 51: 0.6393131965940649
Loss on train for epoch 52: 0.7322464383417561
lr:  [0.00026663855802677353]
Loss on validation for epoch 52: 0.8203001686117866
Loss on train for epoch 53: 0.735320658566151
lr:  [0.0002610835880678824]
Loss on validation for epoch 53: 0.6583869701082056
Loss on train for epoch 54: 0.7285325192975365
lr:  [0.0002555286181089913]
Loss on validation for epoch 54: 0.6568612388589166
Loss on train for epoch 55: 0.7317918841594537
lr:  [0.0002499736481501002]
Loss on validation for epoch 55: 0.7243017716841265
Loss on train for epoch 56: 0.734593977002989
lr:  [0.000244418678191209]
Loss on validation for epoch 56: 0.9854735027660023
Loss on train for epoch 57: 0.7286874326741221
lr:  [0.0002388637082323179]
Loss on validation for epoch 57: 0.7138513638214632
Loss on train for epoch 58: 0.7234745420925531
lr:  [0.0002333087382734268]
Loss on validation for epoch 58: 0.654322013258934
Loss on train for epoch 59: 0.7210392048847517
lr:  [0.00022775376831453566]
Loss on validation for epoch 59: 0.6772530471736734
Loss on train for epoch 60: 0.7198209048335421
lr:  [0.0002221987983556446]
Loss on validation for epoch 60: 0.672101301225749
Model saved at epoch 60
Loss on train for epoch 61: 0.7184354503987184
lr:  [0.00021664382839675346]
Loss on validation for epoch 61: 0.6636219295588407
Loss on train for epoch 62: 0.7132167682136485
lr:  [0.00021108885843786236]
Loss on validation for epoch 62: 0.8153150948611173
Loss on train for epoch 63: 0.71439887376845
lr:  [0.00020553388847897123]
Loss on validation for epoch 63: 0.7197143679315393
Loss on train for epoch 64: 0.7167150522997529
lr:  [0.00019997891852008013]
Loss on validation for epoch 64: 0.7629294178702615
Loss on train for epoch 65: 0.717498266832652
lr:  [0.000194423948561189]
Loss on validation for epoch 65: 0.7941009239716963
Loss on train for epoch 66: 0.7118530842905026
lr:  [0.00018886897860229788]
Loss on validation for epoch 66: 0.6688567928292535
Loss on train for epoch 67: 0.7138377710809292
lr:  [0.00018331400864340678]
Loss on validation for epoch 67: 0.7041027044708078
Loss on train for epoch 68: 0.710136279774798
lr:  [0.00017775903868451565]
Loss on validation for epoch 68: 0.7914036620746959
Loss on train for epoch 69: 0.7116302425427048
lr:  [0.00017220406872562455]
Loss on validation for epoch 69: 0.6839823817664926
Loss on train for epoch 70: 0.7117828436945149
lr:  [0.00016664909876673342]
Loss on validation for epoch 70: 0.7031629613854669
Model saved at epoch 70
Loss on train for epoch 71: 0.7056600210845357
lr:  [0.00016109412880784232]
Loss on validation for epoch 71: 0.7171820104122162
Loss on train for epoch 72: 0.7034249792062807
lr:  [0.0001555391588489512]
Loss on validation for epoch 72: 0.8073073625564575
Loss on train for epoch 73: 0.7066401844345868
lr:  [0.00014998418889006007]
Loss on validation for epoch 73: 0.6465058028697968
Loss on train for epoch 74: 0.7076685818255061
lr:  [0.00014442921893116897]
Loss on validation for epoch 74: 0.7428626282648607
Loss on train for epoch 75: 0.6991847466811736
lr:  [0.00013887424897227784]
Loss on validation for epoch 75: 0.7802129726518284
Loss on train for epoch 76: 0.7010943636835413
lr:  [0.00013331927901338676]
Loss on validation for epoch 76: 0.6652248420498588
Loss on train for epoch 77: 0.6985964557930007
lr:  [0.00012776430905449564]
Loss on validation for epoch 77: 0.6664221869273619
Loss on train for epoch 78: 0.692709307969182
lr:  [0.0001222093390956045]
Loss on validation for epoch 78: 0.6588952785188501
Loss on train for epoch 79: 0.6928415108168148
lr:  [0.0001166543691367134]
Loss on validation for epoch 79: 0.6563236916607077
Loss on train for epoch 80: 0.7021045287261651
lr:  [0.0001110993991778223]
Loss on validation for epoch 80: 0.7230015315792777
Model saved at epoch 80
Loss on train for epoch 81: 0.6945125701531514
lr:  [0.00010554442921893118]
Loss on validation for epoch 81: 0.6893460032614794
Loss on train for epoch 82: 0.6907954174721264
lr:  [9.998945926004007e-05]
Loss on validation for epoch 82: 0.6862794919447466
Loss on train for epoch 83: 0.6926096461755727
lr:  [9.443448930114894e-05]
Loss on validation for epoch 83: 0.6677622131325982
Loss on train for epoch 84: 0.6883405978584651
lr:  [8.887951934225783e-05]
Loss on validation for epoch 84: 0.6850201148878444
Loss on train for epoch 85: 0.684791908827407
lr:  [8.332454938336671e-05]
Loss on validation for epoch 85: 0.6518119817430322
Loss on train for epoch 86: 0.6846212275057635
lr:  [7.77695794244756e-05]
Loss on validation for epoch 86: 0.6582004143433138
Loss on train for epoch 87: 0.6844256630545549
lr:  [7.221460946558448e-05]
Loss on validation for epoch 87: 0.641030643473972
Loss on train for epoch 88: 0.6808978055075404
lr:  [6.665963950669338e-05]
Loss on validation for epoch 88: 0.7048925405198877
Loss on train for epoch 89: 0.6819855886912662
lr:  [6.110466954780225e-05]
Loss on validation for epoch 89: 0.6956033584746447
Loss on train for epoch 90: 0.6796290293703495
lr:  [5.554969958891115e-05]
Loss on validation for epoch 90: 0.6971325251189145
Model saved at epoch 90
Loss on train for epoch 91: 0.6808159514215458
lr:  [4.9994729630020033e-05]
Loss on validation for epoch 91: 0.6713131652636961
Loss on train for epoch 92: 0.6790666607910134
lr:  [4.443975967112891e-05]
Loss on validation for epoch 92: 0.6510823477398265
Loss on train for epoch 93: 0.6720976100022246
lr:  [3.88847897122378e-05]
Loss on validation for epoch 93: 0.7167477838017724
Loss on train for epoch 94: 0.6709840528426632
lr:  [3.332981975334669e-05]
Loss on validation for epoch 94: 0.669945394450968
Loss on train for epoch 95: 0.6745418035893558
lr:  [2.7774849794455574e-05]
Loss on validation for epoch 95: 0.6769671751694246
Loss on train for epoch 96: 0.667955869119579
lr:  [2.2219879835564456e-05]
Loss on validation for epoch 96: 0.7101297337900508
Loss on train for epoch 97: 0.6660016528569317
lr:  [1.6664909876673346e-05]
Loss on validation for epoch 97: 0.676390684463761
Loss on train for epoch 98: 0.6646320799779168
lr:  [1.1109939917782228e-05]
Loss on validation for epoch 98: 0.6919839747927405
Loss on train for epoch 99: 0.6625755164044179
lr:  [5.554969958891114e-06]
Loss on validation for epoch 99: 0.6999450176954269
