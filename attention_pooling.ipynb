{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Definizione della classe AttentionPool2d\n",
    "class AttentionPool2d(nn.Module):\n",
    "    def __init__(self, spacial_dim: int, embed_dim: int, num_heads: int, output_dim: int = None):\n",
    "        super().__init__()\n",
    "        self.positional_embedding = nn.Parameter(torch.randn(spacial_dim * embed_dim + 1, embed_dim) / embed_dim ** 0.5)\n",
    "        self.k_proj = nn.Linear(embed_dim, embed_dim)\n",
    "        self.q_proj = nn.Linear(embed_dim, embed_dim)\n",
    "        self.v_proj = nn.Linear(embed_dim, embed_dim)\n",
    "        self.c_proj = nn.Linear(embed_dim, output_dim or embed_dim)\n",
    "        self.num_heads = num_heads\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x = x.reshape(x.shape[0], x.shape[1], x.shape[2] * x.shape[3]).permute(2, 0, 1)  # NCHW -> (HW)NC\n",
    "        x = x.reshape(x.shape[0], x.shape[1] * x.shape[2]).permute(1, 0)  # N,H,W -> (HW),N\n",
    "\n",
    "        x = torch.cat([x.mean(dim=0, keepdim=True), x], dim=0).unsqueeze(-1)  # (HW+1)NC\n",
    "        pos = self.positional_embedding[:, None, :].to(x.dtype)\n",
    "        print('x', x.shape)\n",
    "        print('pos', pos.shape)\n",
    "        x = x +  pos # Add positional embedding\n",
    "        x, _ = F.multi_head_attention_forward(\n",
    "            query=x, key=x, value=x,\n",
    "            embed_dim_to_check=x.shape[-1],\n",
    "            num_heads=self.num_heads,\n",
    "            q_proj_weight=self.q_proj.weight,\n",
    "            k_proj_weight=self.k_proj.weight,\n",
    "            v_proj_weight=self.v_proj.weight,\n",
    "            in_proj_weight=None,\n",
    "            in_proj_bias=torch.cat([self.q_proj.bias, self.k_proj.bias, self.v_proj.bias]),\n",
    "            bias_k=None,\n",
    "            bias_v=None,\n",
    "            add_zero_attn=False,\n",
    "            dropout_p=0.,\n",
    "            out_proj_weight=self.c_proj.weight,\n",
    "            out_proj_bias=self.c_proj.bias,\n",
    "            use_separate_proj_weight=True,\n",
    "            training=self.training,\n",
    "            need_weights=False\n",
    "        )\n",
    "        print('x_final', x.shape)\n",
    "\n",
    "        return x[:512]\n",
    "\n",
    "# Parametri \n",
    "#dim input-> batch, seq_len, embedded_dim\n",
    "embed_dim = 128\n",
    "N, H, W = 2, embed_dim, 1000 # N = batch size, C = numero di canali, H = altezza, W = larghezza\n",
    "spacial_dim = W  # Supponiamo H e W siano uguali per semplicit√†\n",
    "\n",
    "num_heads = 4\n",
    "\n",
    "\n",
    "# Generazione di un batch di immagini di esempio\n",
    "images = torch.randn(N, H, W).to(device='cuda')\n",
    "print(images.shape)\n",
    "\n",
    "# Inizializzazione dell'Attention Pooling\n",
    "attention_pool = AttentionPool2d(spacial_dim, embed_dim, num_heads).to(device='cuda')\n",
    "\n",
    "# Applicazione dell'Attention Pooling\n",
    "pooled_features = attention_pool(images)\n",
    "\n",
    "# Stampa delle dimensioni dell'output\n",
    "print(f\"Dimensioni dell'output: {pooled_features.shape}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AIE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
