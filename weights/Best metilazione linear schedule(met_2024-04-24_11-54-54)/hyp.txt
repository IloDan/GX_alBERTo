TRAINING HYPERPARAMETERS:
batch_size: 128
device: cuda
optimizer: AdamW
learning_rate: 5e-05
num_epochs: 300
train_test_split: 0
DATASET HYPERPARAMETERS:
k: 8192
center: 65536
max_len: 16384
DATASET SELECTION:
which_dataset: 1
vocab_size: 6
LABEL SELECTION:
label: fpkm_uq_median
MODEL HYPERPARAMETERS:
mask: False
dropout_pe: 0.11
mod: met
d_model: 128
n_head: 4
dim_feedforward: 1024
num_encoder_layers: 1
dropout: 0.04
fc_dim: 128
output_dim: 1
dropout_fc: 0.21
att_mask: False