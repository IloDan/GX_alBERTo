ClearML Task: created new task id=0c0e26aa74f94ebb8f907dbe63b77ea3
ClearML results page: https://app.clear.ml/projects/364457bc04234a8b80e439e974b93968/experiments/0c0e26aa74f94ebb8f907dbe63b77ea3/output/log
leftpos: 32895
rightpos: 98431
maxlen: 65536
batch_size:  32
which_dataset:  1
label:  fpkm_uq_median
Dimensioni dataset di test:`574`
Dimensioni dataset di validazione:`1229`
Dimensioni dataset di train:`10209`
Loss on train for epoch 1: 1.00718208020553
lr:  [0.0005]
Loss on validation for epoch 1: 1.0100696270282452
Loss on train for epoch 2: 0.9985223539173603
lr:  [0.0005]
Loss on validation for epoch 2: 1.0130228568346074
Loss on train for epoch 3: 0.9992878088727594
lr:  [0.0005]
Loss on validation for epoch 3: 1.0078227168474443
Loss on train for epoch 4: 0.9985694237984717
lr:  [0.0005]
Loss on validation for epoch 4: 1.0062680534827404
Loss on train for epoch 5: 1.0013820740394295
lr:  [0.0005]
Loss on validation for epoch 5: 1.0087334697063153
Loss on train for epoch 6: 1.0006909341551364
lr:  [0.0005]
Loss on validation for epoch 6: 1.021810077703916
Loss on train for epoch 7: 0.9979242553876247
lr:  [0.0005]
Loss on validation for epoch 7: 1.0082076604549701
Loss on train for epoch 8: 0.9991658166050911
lr:  [0.0005]
Loss on validation for epoch 8: 1.0081044313235161
Loss on train for epoch 9: 1.0000568073242904
lr:  [0.0005]
Loss on validation for epoch 9: 1.0067917307217915
Loss on train for epoch 10: 0.9978322876093444
lr:  [0.0001]
Loss on validation for epoch 10: 1.0089527842326043
Model saved at epoch 10
Loss on train for epoch 11: 0.9982498218305409
lr:  [0.0001]
Loss on validation for epoch 11: 1.0074316828678815
Loss on train for epoch 12: 0.9989558995701373
lr:  [0.0001]
Loss on validation for epoch 12: 1.0075699931535966
Loss on train for epoch 13: 0.9971519505197648
lr:  [0.0001]
Loss on validation for epoch 13: 1.0068181646175873
Loss on train for epoch 14: 0.9972537575522438
lr:  [0.0001]
Loss on validation for epoch 14: 1.0071566196588368
Loss on train for epoch 15: 0.9974694038089182
lr:  [0.0001]
Loss on validation for epoch 15: 1.0071148780676036
Loss on train for epoch 16: 0.9974305536248721
lr:  [2e-05]
Loss on validation for epoch 16: 1.0067847569783528
Loss on train for epoch 17: 0.9977156640961766
lr:  [2e-05]
Loss on validation for epoch 17: 1.0068431053406153
Loss on train for epoch 18: 0.9987255422398448
lr:  [2e-05]
Loss on validation for epoch 18: 1.0069113648854768
Loss on train for epoch 19: 0.9988969154655933
lr:  [2e-05]
Loss on validation for epoch 19: 1.0069514451882777
Loss on train for epoch 20: 1.0000350925140082
lr:  [2e-05]
Loss on validation for epoch 20: 1.0070391557155511
Model saved at epoch 20
Loss on train for epoch 21: 1.0005177242681385
lr:  [2e-05]
Loss on validation for epoch 21: 1.007010125196897
Loss on train for epoch 22: 0.9991733290255069
lr:  [4.000000000000001e-06]
Loss on validation for epoch 22: 1.0071255243741548
Loss on train for epoch 23: 0.9991801391355694
lr:  [4.000000000000001e-06]
Loss on validation for epoch 23: 1.0071265177849011
Loss on train for epoch 24: 0.9980238952673972
lr:  [4.000000000000001e-06]
Loss on validation for epoch 24: 1.0071262365732438
Loss on train for epoch 25: 0.9976079412735999
lr:  [4.000000000000001e-06]
Loss on validation for epoch 25: 1.0071240250880902
Loss on train for epoch 26: 1.0015764735639094
lr:  [4.000000000000001e-06]
Loss on validation for epoch 26: 1.0071194003789852
Loss on train for epoch 27: 1.0111999085173011
lr:  [4.000000000000001e-06]
Loss on validation for epoch 27: 1.0071058471997578
Loss on train for epoch 28: 0.9980995589634404
lr:  [8.000000000000002e-07]
Loss on validation for epoch 28: 1.0071412982084813
Loss on train for epoch 29: 0.9990707230754197
lr:  [8.000000000000002e-07]
Loss on validation for epoch 29: 1.0071402390797932
Loss on train for epoch 30: 1.0102211941964925
lr:  [8.000000000000002e-07]
Loss on validation for epoch 30: 1.0071360698113074
Model saved at epoch 30
Loss on train for epoch 31: 0.9978109453804791
lr:  [8.000000000000002e-07]
Loss on validation for epoch 31: 1.007130320255573
Loss on train for epoch 32: 0.9989745827391744
lr:  [8.000000000000002e-07]
Loss on validation for epoch 32: 1.007128154620146
Loss on train for epoch 33: 1.0004475980997085
lr:  [8.000000000000002e-07]
Loss on validation for epoch 33: 1.0071309132453723
Loss on train for epoch 34: 0.998765179514885
lr:  [1.6000000000000006e-07]
Loss on validation for epoch 34: 1.0071349052282481
Loss on train for epoch 35: 0.9984315588138998
lr:  [1.6000000000000006e-07]
Loss on validation for epoch 35: 1.0071351405901787
Loss on train for epoch 36: 0.998828926216811
lr:  [1.6000000000000006e-07]
Loss on validation for epoch 36: 1.007134966361217
Loss on train for epoch 37: 0.9988418846391142
lr:  [1.6000000000000006e-07]
Loss on validation for epoch 37: 1.0071348211704156
Loss on train for epoch 38: 0.9975130281993188
lr:  [1.6000000000000006e-07]
Loss on validation for epoch 38: 1.0071355135012896
Loss on train for epoch 39: 1.0083567238412798
lr:  [1.6000000000000006e-07]
Loss on validation for epoch 39: 1.007135319404113
Loss on train for epoch 40: 0.9979242798872292
lr:  [3.2000000000000015e-08]
Loss on validation for epoch 40: 1.007133974478795
Model saved at epoch 40
Loss on train for epoch 41: 0.997333097551018
lr:  [3.2000000000000015e-08]
Loss on validation for epoch 41: 1.0071338567978296
Loss on train for epoch 42: 1.0108819160610438
lr:  [3.2000000000000015e-08]
Loss on validation for epoch 42: 1.0071339255724199
Loss on train for epoch 43: 0.9997768110595644
lr:  [3.2000000000000015e-08]
Loss on validation for epoch 43: 1.0071335985110357
Loss on train for epoch 44: 0.9974579049274326
lr:  [3.2000000000000015e-08]
Loss on validation for epoch 44: 1.0071336840971923
Loss on train for epoch 45: 1.0031021871604024
lr:  [3.2000000000000015e-08]
Loss on validation for epoch 45: 1.0071335557179573
Loss on train for epoch 46: 1.001072679180652
lr:  [6.4000000000000035e-09]
Loss on validation for epoch 46: 1.007133499169961
Loss on train for epoch 47: 0.9983610521070659
lr:  [6.4000000000000035e-09]
Loss on validation for epoch 47: 1.0071335037549336
Loss on train for epoch 48: 0.9983259896747768
lr:  [6.4000000000000035e-09]
Loss on validation for epoch 48: 1.0071335282081213
Loss on train for epoch 49: 0.999147585220635
lr:  [6.4000000000000035e-09]
Loss on validation for epoch 49: 1.0071335022266095
Loss on train for epoch 50: 0.9967719160253182
lr:  [6.4000000000000035e-09]
Loss on validation for epoch 50: 1.007133532793094
Model saved at epoch 50
Loss on train for epoch 51: 0.9981691387714818
lr:  [6.4000000000000035e-09]
Loss on validation for epoch 51: 1.0071335419630394
Loss on train for epoch 52: 1.0010037905536593
lr:  [6.4000000000000035e-09]
Loss on validation for epoch 52: 1.0071335037549336
Loss on train for epoch 53: 1.000972655415535
lr:  [6.4000000000000035e-09]
Loss on validation for epoch 53: 1.0071334869433672
Loss on train for epoch 54: 0.9974216858157888
lr:  [6.4000000000000035e-09]
Loss on validation for epoch 54: 1.0071334777734218
Loss on train for epoch 55: 1.0040432626381517
lr:  [6.4000000000000035e-09]
Loss on validation for epoch 55: 1.0071334976416368
Loss on train for epoch 56: 0.9974556932516861
lr:  [6.4000000000000035e-09]
Loss on validation for epoch 56: 1.0071334410936406
Loss on train for epoch 57: 0.9992521775886416
lr:  [6.4000000000000035e-09]
Loss on validation for epoch 57: 1.0071334349803436
Loss on train for epoch 58: 0.9986404304392635
lr:  [6.4000000000000035e-09]
Loss on validation for epoch 58: 1.0071334395653162
Loss on train for epoch 59: 0.9988997607491911
lr:  [6.4000000000000035e-09]
Loss on validation for epoch 59: 1.0071334395653162
Loss on train for epoch 60: 1.0000105266459287
lr:  [6.4000000000000035e-09]
Loss on validation for epoch 60: 1.0071334410936406
Model saved at epoch 60
Loss on train for epoch 61: 0.9990250717848539
lr:  [6.4000000000000035e-09]
Loss on validation for epoch 61: 1.00713345179191
Loss on train for epoch 62: 0.9992705078795552
lr:  [6.4000000000000035e-09]
Loss on validation for epoch 62: 1.0071334410936406
Loss on train for epoch 63: 0.9971166113854452
lr:  [6.4000000000000035e-09]
Loss on validation for epoch 63: 1.0071334410936406
Loss on train for epoch 64: 1.0025434704497456
lr:  [6.4000000000000035e-09]
Loss on validation for epoch 64: 1.0071334426219647
Loss on train for epoch 65: 0.997850211756304
lr:  [6.4000000000000035e-09]
Loss on validation for epoch 65: 1.007133465546828
Loss on train for epoch 66: 0.998190413787961
lr:  [6.4000000000000035e-09]
Loss on validation for epoch 66: 1.0071334365086677
Loss on train for epoch 67: 0.9983336357399821
lr:  [6.4000000000000035e-09]
Loss on validation for epoch 67: 1.007133431923695
Loss on train for epoch 68: 0.9971304059028625
lr:  [6.4000000000000035e-09]
Loss on validation for epoch 68: 1.0071334151121287
Loss on train for epoch 69: 1.0025614276528358
lr:  [6.4000000000000035e-09]
Loss on validation for epoch 69: 1.0071334105271559
Loss on train for epoch 70: 0.997477549710311
lr:  [6.4000000000000035e-09]
Loss on validation for epoch 70: 1.007133424282074
Model saved at epoch 70
Loss on train for epoch 71: 1.0020423578098416
lr:  [6.4000000000000035e-09]
Loss on validation for epoch 71: 1.0071334410936406
Loss on train for epoch 72: 1.0095776949077844
lr:  [6.4000000000000035e-09]
Loss on validation for epoch 72: 1.0071334227537498
Loss on train for epoch 73: 1.0102846972644328
lr:  [6.4000000000000035e-09]
Loss on validation for epoch 73: 1.007133350922511
Loss on train for epoch 74: 1.005734925251454
lr:  [6.4000000000000035e-09]
Loss on validation for epoch 74: 1.007133282147921
Loss on train for epoch 75: 1.0073562075383962
lr:  [6.4000000000000035e-09]
Loss on validation for epoch 75: 1.0071332668646789
Loss on train for epoch 76: 1.003179839719087
lr:  [6.4000000000000035e-09]
Loss on validation for epoch 76: 1.0071332378265185
Loss on train for epoch 77: 0.9986901752650738
lr:  [6.4000000000000035e-09]
Loss on validation for epoch 77: 1.007133146127065
Loss on train for epoch 78: 0.9985822465270757
lr:  [6.4000000000000035e-09]
Loss on validation for epoch 78: 1.0071331491837134
Loss on train for epoch 79: 0.9982217029668391
lr:  [6.4000000000000035e-09]
Loss on validation for epoch 79: 1.0071332133733308
Loss on train for epoch 80: 0.9974059508705977
lr:  [6.4000000000000035e-09]
Loss on validation for epoch 80: 1.0071332194866278
Model saved at epoch 80
Loss on train for epoch 81: 1.0006123328581453
lr:  [6.4000000000000035e-09]
Loss on validation for epoch 81: 1.0071331858634949
Loss on train for epoch 82: 0.997596902307123
lr:  [6.4000000000000035e-09]
Loss on validation for epoch 82: 1.007133228656573
Loss on train for epoch 83: 1.0012885050848126
lr:  [6.4000000000000035e-09]
Loss on validation for epoch 83: 1.0071332103166826
Loss on train for epoch 84: 1.0002615970559419
lr:  [6.4000000000000035e-09]
Loss on validation for epoch 84: 1.0071331629386315
Loss on train for epoch 85: 0.998865766171366
lr:  [6.4000000000000035e-09]
Loss on validation for epoch 85: 1.0071331308438227
Loss on train for epoch 86: 0.9987394915893674
lr:  [6.4000000000000035e-09]
Loss on validation for epoch 86: 1.0071331308438227
Loss on train for epoch 87: 0.9978080495260656
lr:  [6.4000000000000035e-09]
Loss on validation for epoch 87: 1.0071331308438227
Loss on train for epoch 88: 0.9965397082967684
lr:  [6.4000000000000035e-09]
Loss on validation for epoch 88: 1.0071331384854438
Loss on train for epoch 89: 0.9991556851193308
lr:  [6.4000000000000035e-09]
Loss on validation for epoch 89: 1.0071331109756079
Loss on train for epoch 90: 1.0042622015811502
lr:  [6.4000000000000035e-09]
Loss on validation for epoch 90: 1.0071331216738775
Model saved at epoch 90
Loss on train for epoch 91: 0.9972014805302024
lr:  [6.4000000000000035e-09]
Loss on validation for epoch 91: 1.0071331751652253
Loss on train for epoch 92: 0.99862612914294
lr:  [6.4000000000000035e-09]
Loss on validation for epoch 92: 1.0071331980900886
Loss on train for epoch 93: 0.9977314292016672
lr:  [6.4000000000000035e-09]
Loss on validation for epoch 93: 1.0071331950334401
Loss on train for epoch 94: 1.001802610233426
lr:  [6.4000000000000035e-09]
Loss on validation for epoch 94: 1.0071331965617645
Loss on train for epoch 95: 0.9975989301688969
lr:  [6.4000000000000035e-09]
Loss on validation for epoch 95: 1.007133091107393
Loss on train for epoch 96: 0.9974505174497608
lr:  [6.4000000000000035e-09]
Loss on validation for epoch 96: 1.007133084994096
Loss on train for epoch 97: 0.9997152959927916
lr:  [6.4000000000000035e-09]
Loss on validation for epoch 97: 1.0071331384854438
Loss on train for epoch 98: 1.0028537683188916
lr:  [6.4000000000000035e-09]
Loss on validation for epoch 98: 1.0071331232022016
Loss on train for epoch 99: 0.9993221546523273
lr:  [6.4000000000000035e-09]
Loss on validation for epoch 99: 1.007133199618413
Loss on train for epoch 100: 0.9980675049126149
lr:  [6.4000000000000035e-09]
Loss on validation for epoch 100: 1.0071332057317097
Model saved at epoch 100
