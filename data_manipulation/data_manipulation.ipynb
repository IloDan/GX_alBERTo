{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMPRIMO IL VETTORE DI METILAZIONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gene_id</th>\n",
       "      <th>gene_type</th>\n",
       "      <th>split</th>\n",
       "      <th>labels</th>\n",
       "      <th>gene_name</th>\n",
       "      <th>TSS</th>\n",
       "      <th>chromosome_name</th>\n",
       "      <th>strand</th>\n",
       "      <th>fpkm_median</th>\n",
       "      <th>tpm_median</th>\n",
       "      <th>fpkm_uq_median</th>\n",
       "      <th>Seq</th>\n",
       "      <th>array</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ENSG00000198691</td>\n",
       "      <td>protein_coding</td>\n",
       "      <td>test</td>\n",
       "      <td>-1.201834</td>\n",
       "      <td>ABCA4</td>\n",
       "      <td>94121177</td>\n",
       "      <td>chr1</td>\n",
       "      <td>-</td>\n",
       "      <td>-1.112163</td>\n",
       "      <td>0.309409</td>\n",
       "      <td>-0.892446</td>\n",
       "      <td>[1, 3, 2, 2, 0, 1, 0, 1, 0, 1, 1, 0, 0, 3, 3, ...</td>\n",
       "      <td>(0, 90854)\\t0.01985548622906208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENSG00000135776</td>\n",
       "      <td>protein_coding</td>\n",
       "      <td>train</td>\n",
       "      <td>0.573164</td>\n",
       "      <td>ABCB10</td>\n",
       "      <td>229558730</td>\n",
       "      <td>chr1</td>\n",
       "      <td>-</td>\n",
       "      <td>2.044114</td>\n",
       "      <td>3.543001</td>\n",
       "      <td>2.229126</td>\n",
       "      <td>[0, 2, 0, 2, 2, 0, 2, 3, 2, 2, 3, 0, 0, 2, 0, ...</td>\n",
       "      <td>(0, 76414)\\t0.17362597584724426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ENSG00000143322</td>\n",
       "      <td>protein_coding</td>\n",
       "      <td>train</td>\n",
       "      <td>0.488895</td>\n",
       "      <td>ABL2</td>\n",
       "      <td>179143084</td>\n",
       "      <td>chr1</td>\n",
       "      <td>-</td>\n",
       "      <td>0.688583</td>\n",
       "      <td>2.139535</td>\n",
       "      <td>0.873813</td>\n",
       "      <td>[3, 2, 3, 2, 1, 1, 0, 0, 3, 2, 0, 2, 1, 3, 2, ...</td>\n",
       "      <td>(0, 120866)\\t0.024935100227594376\\n  (0, 122...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ENSG00000131584</td>\n",
       "      <td>protein_coding</td>\n",
       "      <td>train</td>\n",
       "      <td>0.798138</td>\n",
       "      <td>ACAP3</td>\n",
       "      <td>1307938</td>\n",
       "      <td>chr1</td>\n",
       "      <td>-</td>\n",
       "      <td>1.848998</td>\n",
       "      <td>3.319618</td>\n",
       "      <td>1.992406</td>\n",
       "      <td>[1, 0, 1, 1, 1, 1, 2, 1, 0, 1, 2, 0, 2, 1, 3, ...</td>\n",
       "      <td>(0, 42837)\\t0.016621699556708336\\n  (0, 9995...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENSG00000182827</td>\n",
       "      <td>protein_coding</td>\n",
       "      <td>valid</td>\n",
       "      <td>1.077838</td>\n",
       "      <td>ACBD3</td>\n",
       "      <td>226186763</td>\n",
       "      <td>chr1</td>\n",
       "      <td>-</td>\n",
       "      <td>4.172536</td>\n",
       "      <td>5.655054</td>\n",
       "      <td>4.329461</td>\n",
       "      <td>[1, 2, 0, 3, 1, 3, 1, 0, 2, 1, 3, 1, 0, 1, 3, ...</td>\n",
       "      <td>(0, 8334)\\t0.6710221171379089\\n  (0, 129134)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18013</th>\n",
       "      <td>ENSG00000235961</td>\n",
       "      <td>protein_coding</td>\n",
       "      <td>train</td>\n",
       "      <td>-0.499574</td>\n",
       "      <td>PNMA6A</td>\n",
       "      <td>152240819</td>\n",
       "      <td>chrX</td>\n",
       "      <td>+</td>\n",
       "      <td>0.470094</td>\n",
       "      <td>1.984990</td>\n",
       "      <td>0.647637</td>\n",
       "      <td>[3, 0, 3, 2, 1, 1, 0, 3, 1, 1, 0, 1, 1, 0, 0, ...</td>\n",
       "      <td>(0, 48807)\\t0.6558285355567932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18014</th>\n",
       "      <td>ENSG00000236362</td>\n",
       "      <td>protein_coding</td>\n",
       "      <td>train</td>\n",
       "      <td>-1.463212</td>\n",
       "      <td>GAGE12F</td>\n",
       "      <td>49325479</td>\n",
       "      <td>chrX</td>\n",
       "      <td>+</td>\n",
       "      <td>-7.643856</td>\n",
       "      <td>-7.643856</td>\n",
       "      <td>-7.643856</td>\n",
       "      <td>[4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18015</th>\n",
       "      <td>ENSG00000237671</td>\n",
       "      <td>protein_coding</td>\n",
       "      <td>train</td>\n",
       "      <td>-1.463212</td>\n",
       "      <td>GAGE12C</td>\n",
       "      <td>49296814</td>\n",
       "      <td>chrX</td>\n",
       "      <td>+</td>\n",
       "      <td>-7.643856</td>\n",
       "      <td>-7.643856</td>\n",
       "      <td>-7.643856</td>\n",
       "      <td>[1, 2, 0, 1, 1, 1, 0, 2, 1, 0, 3, 3, 0, 3, 0, ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18016</th>\n",
       "      <td>ENSG00000243978</td>\n",
       "      <td>protein_coding</td>\n",
       "      <td>train</td>\n",
       "      <td>-1.148857</td>\n",
       "      <td>RTL9</td>\n",
       "      <td>109662285</td>\n",
       "      <td>chrX</td>\n",
       "      <td>+</td>\n",
       "      <td>-5.078259</td>\n",
       "      <td>-3.721658</td>\n",
       "      <td>-4.891108</td>\n",
       "      <td>[0, 3, 1, 3, 1, 0, 0, 2, 0, 3, 0, 3, 3, 3, 1, ...</td>\n",
       "      <td>(0, 65113)\\t0.1490333527326584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18017</th>\n",
       "      <td>ENSG00000257529</td>\n",
       "      <td>protein_coding</td>\n",
       "      <td>test</td>\n",
       "      <td>2.140827</td>\n",
       "      <td>RPL36A-HNRNPH2</td>\n",
       "      <td>100645999</td>\n",
       "      <td>chrX</td>\n",
       "      <td>+</td>\n",
       "      <td>-7.643856</td>\n",
       "      <td>-7.643856</td>\n",
       "      <td>-7.643856</td>\n",
       "      <td>[0, 3, 2, 0, 3, 2, 1, 0, 1, 0, 0, 0, 3, 1, 1, ...</td>\n",
       "      <td>(0, 23602)\\t0.10895410925149918\\n  (0, 60040...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18018 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               gene_id       gene_type  split    labels       gene_name  \\\n",
       "0      ENSG00000198691  protein_coding   test -1.201834           ABCA4   \n",
       "1      ENSG00000135776  protein_coding  train  0.573164          ABCB10   \n",
       "2      ENSG00000143322  protein_coding  train  0.488895            ABL2   \n",
       "3      ENSG00000131584  protein_coding  train  0.798138           ACAP3   \n",
       "4      ENSG00000182827  protein_coding  valid  1.077838           ACBD3   \n",
       "...                ...             ...    ...       ...             ...   \n",
       "18013  ENSG00000235961  protein_coding  train -0.499574          PNMA6A   \n",
       "18014  ENSG00000236362  protein_coding  train -1.463212         GAGE12F   \n",
       "18015  ENSG00000237671  protein_coding  train -1.463212         GAGE12C   \n",
       "18016  ENSG00000243978  protein_coding  train -1.148857            RTL9   \n",
       "18017  ENSG00000257529  protein_coding   test  2.140827  RPL36A-HNRNPH2   \n",
       "\n",
       "             TSS chromosome_name strand  fpkm_median  tpm_median  \\\n",
       "0       94121177            chr1      -    -1.112163    0.309409   \n",
       "1      229558730            chr1      -     2.044114    3.543001   \n",
       "2      179143084            chr1      -     0.688583    2.139535   \n",
       "3        1307938            chr1      -     1.848998    3.319618   \n",
       "4      226186763            chr1      -     4.172536    5.655054   \n",
       "...          ...             ...    ...          ...         ...   \n",
       "18013  152240819            chrX      +     0.470094    1.984990   \n",
       "18014   49325479            chrX      +    -7.643856   -7.643856   \n",
       "18015   49296814            chrX      +    -7.643856   -7.643856   \n",
       "18016  109662285            chrX      +    -5.078259   -3.721658   \n",
       "18017  100645999            chrX      +    -7.643856   -7.643856   \n",
       "\n",
       "       fpkm_uq_median                                                Seq  \\\n",
       "0           -0.892446  [1, 3, 2, 2, 0, 1, 0, 1, 0, 1, 1, 0, 0, 3, 3, ...   \n",
       "1            2.229126  [0, 2, 0, 2, 2, 0, 2, 3, 2, 2, 3, 0, 0, 2, 0, ...   \n",
       "2            0.873813  [3, 2, 3, 2, 1, 1, 0, 0, 3, 2, 0, 2, 1, 3, 2, ...   \n",
       "3            1.992406  [1, 0, 1, 1, 1, 1, 2, 1, 0, 1, 2, 0, 2, 1, 3, ...   \n",
       "4            4.329461  [1, 2, 0, 3, 1, 3, 1, 0, 2, 1, 3, 1, 0, 1, 3, ...   \n",
       "...               ...                                                ...   \n",
       "18013        0.647637  [3, 0, 3, 2, 1, 1, 0, 3, 1, 1, 0, 1, 1, 0, 0, ...   \n",
       "18014       -7.643856  [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, ...   \n",
       "18015       -7.643856  [1, 2, 0, 1, 1, 1, 0, 2, 1, 0, 3, 3, 0, 3, 0, ...   \n",
       "18016       -4.891108  [0, 3, 1, 3, 1, 0, 0, 2, 0, 3, 0, 3, 3, 3, 1, ...   \n",
       "18017       -7.643856  [0, 3, 2, 0, 3, 2, 1, 0, 1, 0, 0, 0, 3, 1, 1, ...   \n",
       "\n",
       "                                                   array  \n",
       "0                        (0, 90854)\\t0.01985548622906208  \n",
       "1                        (0, 76414)\\t0.17362597584724426  \n",
       "2        (0, 120866)\\t0.024935100227594376\\n  (0, 122...  \n",
       "3        (0, 42837)\\t0.016621699556708336\\n  (0, 9995...  \n",
       "4        (0, 8334)\\t0.6710221171379089\\n  (0, 129134)...  \n",
       "...                                                  ...  \n",
       "18013                     (0, 48807)\\t0.6558285355567932  \n",
       "18014                                                     \n",
       "18015                                                     \n",
       "18016                     (0, 65113)\\t0.1490333527326584  \n",
       "18017    (0, 23602)\\t0.10895410925149918\\n  (0, 60040...  \n",
       "\n",
       "[18018 rows x 13 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "df0 = pd.read_hdf('../dataset/Dataset/alberto_seq_array_0.h5', key='1234', mode='r')\n",
    "df0 = pd.read_hdf('../dataset/Dataset/alberto_seq_array_0.h5', key='1234', mode='r')\n",
    "df0 = pd.read_hdf('../dataset/Dataset/alberto_seq_array_0.h5', key='1234', mode='r')\n",
    "df1 = pd.read_hdf('../dataset/Dataset/alberto_seq_array_1.h5', key='1234', mode='r')\n",
    "df2 = pd.read_hdf('../dataset/Dataset/alberto_seq_array_2.h5', key='1234', mode='r')\n",
    "df3 = pd.read_hdf('../dataset/Dataset/alberto_seq_array_3.h5', key='1234', mode='r')\n",
    "df4 = pd.read_hdf('../dataset/Dataset/alberto_seq_array_4.h5', key='1234', mode='r')\n",
    "df5 = pd.read_hdf('../dataset/Dataset/alberto_seq_array_5.h5', key='1234', mode='r')\n",
    "df6 = pd.read_hdf('../dataset/Dataset/alberto_seq_array_6.h5', key='1234', mode='r')\n",
    "df7 = pd.read_hdf('../dataset/Dataset/alberto_seq_array_7.h5', key='1234', mode='r')\n",
    "df8 = pd.read_hdf('../dataset/Dataset/alberto_seq_array_8.h5', key='1234', mode='r')\n",
    "df9 = pd.read_hdf('../dataset/Dataset/alberto_seq_array_9.h5', key='1234', mode='r')\n",
    "\n",
    "dataset = pd.concat([df0, df1, df2, df3, df4, df5, df6, df7, df8, df9])\n",
    "dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(dataset[dataset['split']=='train'][['fpkm_uq_median']])\n",
    "dataset['fpkm_uq_median'] = scaler.transform(dataset[['fpkm_uq_median']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjAAAAGdCAYAAAAMm0nCAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/H5lhTAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAmdklEQVR4nO3df3BU9b3/8deGkB8CuyFgdtkxwdzWQaIULT/i+oORkiH8KPcyTe3NNVfTNgP3chN6MYgkbUGxajR4FUJTIp0WnCmMXmcutI3XaG5Q0qsxhHBz0QipTtFEuJvQidk1cUgC2e8f/XKmC1ED7mbzWZ6PmTPDns/n7HmfM7D74nM+56wtEAgEBAAAYJCYSBcAAABwuQgwAADAOAQYAABgHAIMAAAwDgEGAAAYhwADAACMQ4ABAADGIcAAAADjxEa6gHAZGhrS6dOnNWnSJNlstkiXAwAARiAQCOjTTz+V2+1WTMznj7NEbYA5ffq0UlNTI10GAAC4Ah0dHbruuus+tz1qA8ykSZMk/eUE2O32CFcDAABGwu/3KzU11foe/zxRG2AuXDay2+0EGAAADPNl0z+YxAsAAIxDgAEAAMYhwAAAAOMQYAAAgHEIMAAAwDgEGAAAYBwCDAAAMA4BBgAAGIcAAwAAjEOAAQAAxiHAAAAA4xBgAACAcS47wNTX12vFihVyu92y2Ww6cODA5/b953/+Z9lsNm3bti1ofXd3t/Ly8mS325WUlKSCggL19vYG9Tl27JjuuusuJSQkKDU1VeXl5ZdbKgAAiFKXHWD6+vo0e/ZsVVZWfmG//fv36+2335bb7b6kLS8vT62traqtrVV1dbXq6+u1evVqq93v92vx4sWaPn26mpubtXXrVj3yyCPatWvX5ZYLAACiUOzlbrB06VItXbr0C/ucOnVKa9eu1auvvqrly5cHtR0/flw1NTVqamrS3LlzJUk7duzQsmXL9PTTT8vtdmvv3r0aGBjQr3/9a8XFxemmm25SS0uLnnnmmaCgEynXl7x8yboPn1w+TE8AABAOIZ8DMzQ0pPvuu08bNmzQTTfddEl7Q0ODkpKSrPAiSVlZWYqJiVFjY6PVZ8GCBYqLi7P6ZGdnq62tTZ988smw++3v75ff7w9aAABAdAp5gHnqqacUGxurH/3oR8O2e71epaSkBK2LjY1VcnKyvF6v1cfpdAb1ufD6Qp+LlZWVyeFwWEtqaupXPRQAADBGhTTANDc3a/v27dqzZ49sNlso3/pLlZaWyufzWUtHR8eo7h8AAIyekAaYP/zhD+rq6lJaWppiY2MVGxurjz76SOvXr9f1118vSXK5XOrq6gra7ty5c+ru7pbL5bL6dHZ2BvW58PpCn4vFx8fLbrcHLQAAIDqFNMDcd999OnbsmFpaWqzF7XZrw4YNevXVVyVJHo9HPT09am5utrY7ePCghoaGlJmZafWpr6/X4OCg1ae2tlYzZszQ5MmTQ1kyAAAw0GXfhdTb26sPPvjAen3y5Em1tLQoOTlZaWlpmjJlSlD/8ePHy+VyacaMGZKkmTNnasmSJVq1apWqqqo0ODiooqIi5ebmWrdc33vvvdqyZYsKCgq0ceNGvfvuu9q+fbueffbZr3KsAAAgSlx2gDly5IgWLlxovS4uLpYk5efna8+ePSN6j71796qoqEiLFi1STEyMcnJyVFFRYbU7HA699tprKiws1Jw5czR16lRt3rx5TNxCDQAAIs8WCAQCkS4iHPx+vxwOh3w+X8jnw/AcGAAAwmOk39/8FhIAADAOAQYAABiHAAMAAIxDgAEAAMYhwAAAAOMQYAAAgHEIMAAAwDgEGAAAYBwCDAAAMA4BBgAAGIcAAwAAjEOAAQAAxiHAAAAA4xBgAACAcQgwAADAOAQYAABgHAIMAAAwDgEGAAAYhwADAACMQ4ABAADGIcAAAADjEGAAAIBxCDAAAMA4BBgAAGAcAgwAADAOAQYAABiHAAMAAIxDgAEAAMYhwAAAAOMQYAAAgHEIMAAAwDgEGAAAYBwCDAAAMA4BBgAAGIcAAwAAjEOAAQAAxiHAAAAA4xBgAACAcQgwAADAOJcdYOrr67VixQq53W7ZbDYdOHDAahscHNTGjRs1a9YsTZgwQW63W/fff79Onz4d9B7d3d3Ky8uT3W5XUlKSCgoK1NvbG9Tn2LFjuuuuu5SQkKDU1FSVl5df2RECAICoc9kBpq+vT7Nnz1ZlZeUlbZ999pmOHj2qTZs26ejRo/qP//gPtbW16W//9m+D+uXl5am1tVW1tbWqrq5WfX29Vq9ebbX7/X4tXrxY06dPV3Nzs7Zu3apHHnlEu3btuoJDBAAA0cYWCAQCV7yxzab9+/dr5cqVn9unqalJ8+fP10cffaS0tDQdP35cGRkZampq0ty5cyVJNTU1WrZsmT7++GO53W7t3LlTP/nJT+T1ehUXFydJKikp0YEDB3TixIkR1eb3++VwOOTz+WS326/0EId1fcnLl6z78MnlId0HAABXo5F+f4d9DozP55PNZlNSUpIkqaGhQUlJSVZ4kaSsrCzFxMSosbHR6rNgwQIrvEhSdna22tra9Mknnwy7n/7+fvn9/qAFAABEp7AGmLNnz2rjxo36h3/4BytFeb1epaSkBPWLjY1VcnKyvF6v1cfpdAb1ufD6Qp+LlZWVyeFwWEtqamqoDwcAAIwRYQswg4OD+t73vqdAIKCdO3eGazeW0tJS+Xw+a+no6Aj7PgEAQGTEhuNNL4SXjz76SAcPHgy6huVyudTV1RXU/9y5c+ru7pbL5bL6dHZ2BvW58PpCn4vFx8crPj4+lIcBAADGqJCPwFwIL++//77+67/+S1OmTAlq93g86unpUXNzs7Xu4MGDGhoaUmZmptWnvr5eg4ODVp/a2lrNmDFDkydPDnXJAADAMJcdYHp7e9XS0qKWlhZJ0smTJ9XS0qL29nYNDg7qu9/9ro4cOaK9e/fq/Pnz8nq98nq9GhgYkCTNnDlTS5Ys0apVq3T48GG9+eabKioqUm5urtxutyTp3nvvVVxcnAoKCtTa2qoXX3xR27dvV3FxceiOHAAAGOuyb6N+4403tHDhwkvW5+fn65FHHlF6evqw273++uu6++67Jf3lQXZFRUX6/e9/r5iYGOXk5KiiokITJ060+h87dkyFhYVqamrS1KlTtXbtWm3cuHHEdXIbNQAA5hnp9/dXeg7MWEaAAQDAPGPmOTAAAAChRoABAADGIcAAAADjEGAAAIBxCDAAAMA4BBgAAGAcAgwAADAOAQYAABiHAAMAAIxDgAEAAMYhwAAAAOMQYAAAgHEIMAAAwDgEGAAAYBwCDAAAMA4BBgAAGIcAAwAAjEOAAQAAxiHAAAAA4xBgAACAcQgwAADAOAQYAABgHAIMAAAwDgEGAAAYhwADAACMQ4ABAADGIcAAAADjEGAAAIBxCDAAAMA4BBgAAGAcAgwAADAOAQYAABiHAAMAAIxDgAEAAMYhwAAAAOMQYAAAgHEIMAAAwDgEGAAAYBwCDAAAMM5lB5j6+nqtWLFCbrdbNptNBw4cCGoPBALavHmzpk2bpsTERGVlZen9998P6tPd3a28vDzZ7XYlJSWpoKBAvb29QX2OHTumu+66SwkJCUpNTVV5efnlHx0AAIhKlx1g+vr6NHv2bFVWVg7bXl5eroqKClVVVamxsVETJkxQdna2zp49a/XJy8tTa2uramtrVV1drfr6eq1evdpq9/v9Wrx4saZPn67m5mZt3bpVjzzyiHbt2nUFhwgAAKKNLRAIBK54Y5tN+/fv18qVKyX9ZfTF7XZr/fr1evDBByVJPp9PTqdTe/bsUW5uro4fP66MjAw1NTVp7ty5kqSamhotW7ZMH3/8sdxut3bu3Kmf/OQn8nq9iouLkySVlJTowIEDOnHixIhq8/v9cjgc8vl8stvtV3qIw7q+5OVL1n345PKQ7gMAgKvRSL+/QzoH5uTJk/J6vcrKyrLWORwOZWZmqqGhQZLU0NCgpKQkK7xIUlZWlmJiYtTY2Gj1WbBggRVeJCk7O1ttbW365JNPht13f3+//H5/0AIAAKJTSAOM1+uVJDmdzqD1TqfTavN6vUpJSQlqj42NVXJyclCf4d7jr/dxsbKyMjkcDmtJTU396gcEAADGpKi5C6m0tFQ+n89aOjo6Il0SAAAIk5AGGJfLJUnq7OwMWt/Z2Wm1uVwudXV1BbWfO3dO3d3dQX2Ge4+/3sfF4uPjZbfbgxYAABCdQhpg0tPT5XK5VFdXZ63z+/1qbGyUx+ORJHk8HvX09Ki5udnqc/DgQQ0NDSkzM9PqU19fr8HBQatPbW2tZsyYocmTJ4eyZAAAYKDLDjC9vb1qaWlRS0uLpL9M3G1paVF7e7tsNpvWrVunxx57TL/73e/0zjvv6P7775fb7bbuVJo5c6aWLFmiVatW6fDhw3rzzTdVVFSk3Nxcud1uSdK9996ruLg4FRQUqLW1VS+++KK2b9+u4uLikB04AAAwV+zlbnDkyBEtXLjQen0hVOTn52vPnj166KGH1NfXp9WrV6unp0d33nmnampqlJCQYG2zd+9eFRUVadGiRYqJiVFOTo4qKiqsdofDoddee02FhYWaM2eOpk6dqs2bNwc9KwYAAFy9vtJzYMYyngMDAIB5IvIcGAAAgNFAgAEAAMYhwAAAAOMQYAAAgHEIMAAAwDgEGAAAYBwCDAAAMA4BBgAAGIcAAwAAjEOAAQAAxiHAAAAA4xBgAACAcQgwAADAOAQYAABgHAIMAAAwDgEGAAAYhwADAACMQ4ABAADGIcAAAADjEGAAAIBxCDAAAMA4BBgAAGAcAgwAADAOAQYAABiHAAMAAIxDgAEAAMYhwAAAAOMQYAAAgHEIMAAAwDgEGAAAYBwCDAAAMA4BBgAAGIcAAwAAjEOAAQAAxiHAAAAA4xBgAACAcQgwAADAOAQYAABgHAIMAAAwTsgDzPnz57Vp0yalp6crMTFRX/va1/Szn/1MgUDA6hMIBLR582ZNmzZNiYmJysrK0vvvvx/0Pt3d3crLy5PdbldSUpIKCgrU29sb6nIBAICBQh5gnnrqKe3cuVM///nPdfz4cT311FMqLy/Xjh07rD7l5eWqqKhQVVWVGhsbNWHCBGVnZ+vs2bNWn7y8PLW2tqq2tlbV1dWqr6/X6tWrQ10uAAAwkC3w10MjIfDtb39bTqdTv/rVr6x1OTk5SkxM1G9+8xsFAgG53W6tX79eDz74oCTJ5/PJ6XRqz549ys3N1fHjx5WRkaGmpibNnTtXklRTU6Nly5bp448/ltvt/tI6/H6/HA6HfD6f7HZ7KA9R15e8fMm6D59cHtJ9AABwNRrp93fIR2Buv/121dXV6Y9//KMk6X//93/13//931q6dKkk6eTJk/J6vcrKyrK2cTgcyszMVENDgySpoaFBSUlJVniRpKysLMXExKixsXHY/fb398vv9wctAAAgOsWG+g1LSkrk9/t14403aty4cTp//rwef/xx5eXlSZK8Xq8kyel0Bm3ndDqtNq/Xq5SUlOBCY2OVnJxs9blYWVmZtmzZEurDAQAAY1DIR2D+/d//XXv37tW+fft09OhRPf/883r66af1/PPPh3pXQUpLS+Xz+aylo6MjrPsDAACRE/IRmA0bNqikpES5ubmSpFmzZumjjz5SWVmZ8vPz5XK5JEmdnZ2aNm2atV1nZ6duueUWSZLL5VJXV1fQ+547d07d3d3W9heLj49XfHx8qA8HAACMQSEfgfnss88UExP8tuPGjdPQ0JAkKT09XS6XS3V1dVa73+9XY2OjPB6PJMnj8ainp0fNzc1Wn4MHD2poaEiZmZmhLhkAABgm5CMwK1as0OOPP660tDTddNNN+p//+R8988wz+uEPfyhJstlsWrdunR577DHdcMMNSk9P16ZNm+R2u7Vy5UpJ0syZM7VkyRKtWrVKVVVVGhwcVFFRkXJzc0d0BxIAAIhuIQ8wO3bs0KZNm/Qv//Iv6urqktvt1j/90z9p8+bNVp+HHnpIfX19Wr16tXp6enTnnXeqpqZGCQkJVp+9e/eqqKhIixYtUkxMjHJyclRRURHqcgEAgIFC/hyYsYLnwAAAYJ6IPQcGAAAg3AgwAADAOAQYAABgHAIMAAAwDgEGAAAYhwADAACMQ4ABAADGIcAAAADjEGAAAIBxCDAAAMA4BBgAAGAcAgwAADAOAQYAABiHAAMAAIxDgAEAAMYhwAAAAOMQYAAAgHEIMAAAwDgEGAAAYBwCDAAAMA4BBgAAGIcAAwAAjEOAAQAAxiHAAAAA4xBgAACAcQgwAADAOAQYAABgHAIMAAAwDgEGAAAYhwADAACMQ4ABAADGIcAAAADjEGAAAIBxCDAAAMA4BBgAAGAcAgwAADAOAQYAABiHAAMAAIxDgAEAAMYJS4A5deqU/vEf/1FTpkxRYmKiZs2apSNHjljtgUBAmzdv1rRp05SYmKisrCy9//77Qe/R3d2tvLw82e12JSUlqaCgQL29veEoFwAAGCbkAeaTTz7RHXfcofHjx+uVV17Re++9p3/7t3/T5MmTrT7l5eWqqKhQVVWVGhsbNWHCBGVnZ+vs2bNWn7y8PLW2tqq2tlbV1dWqr6/X6tWrQ10uAAAwkC0QCARC+YYlJSV688039Yc//GHY9kAgILfbrfXr1+vBBx+UJPl8PjmdTu3Zs0e5ubk6fvy4MjIy1NTUpLlz50qSampqtGzZMn388cdyu91fWoff75fD4ZDP55Pdbg/dAUq6vuTlS9Z9+OTykO4DAICr0Ui/v0M+AvO73/1Oc+fO1T333KOUlBTdeuut+uUvf2m1nzx5Ul6vV1lZWdY6h8OhzMxMNTQ0SJIaGhqUlJRkhRdJysrKUkxMjBobG4fdb39/v/x+f9ACAACiU8gDzJ/+9Cft3LlTN9xwg1599VWtWbNGP/rRj/T8889LkrxeryTJ6XQGbed0Oq02r9erlJSUoPbY2FglJydbfS5WVlYmh8NhLampqaE+NAAAMEaEPMAMDQ3pm9/8pp544gndeuutWr16tVatWqWqqqpQ7ypIaWmpfD6ftXR0dIR1fwAAIHJCHmCmTZumjIyMoHUzZ85Ue3u7JMnlckmSOjs7g/p0dnZabS6XS11dXUHt586dU3d3t9XnYvHx8bLb7UELAACITiEPMHfccYfa2tqC1v3xj3/U9OnTJUnp6elyuVyqq6uz2v1+vxobG+XxeCRJHo9HPT09am5utvocPHhQQ0NDyszMDHXJAADAMLGhfsMHHnhAt99+u5544gl973vf0+HDh7Vr1y7t2rVLkmSz2bRu3To99thjuuGGG5Senq5NmzbJ7XZr5cqVkv4yYrNkyRLr0tPg4KCKioqUm5s7ojuQAABAdAt5gJk3b57279+v0tJSPfroo0pPT9e2bduUl5dn9XnooYfU19en1atXq6enR3feeadqamqUkJBg9dm7d6+Kioq0aNEixcTEKCcnRxUVFaEuFwAAGCjkz4EZK3gODAAA5onYc2AAAADCjQADAACMQ4ABAADGIcAAAADjEGAAAIBxCDAAAMA4BBgAAGCckD/IDgAigeczAVcXRmAAAIBxCDAAAMA4BBgAAGAcAgwAADAOk3gBXDWY6AtED0ZgAACAcRiBARC1hhtxARAdGIEBAADGIcAAAADjEGAAAIBxCDAAAMA4BBgAAGAc7kICMObx/BYAFyPAADASt0gDVzcCDAD8FUZ7ADMQYABc1RjJAczEJF4AAGAcAgwAADAOAQYAABiHOTAAxpyxNi/l4nqY1AtEHiMwAADAOAQYAABgHAIMAAAwDgEGAAAYhwADAACMw11IACJqrN1xBMAMjMAAAADjMAIDACHAs2KA0cUIDAAAMA4jMADCZrj5LYxMAAgFAgyAUcWkXQChEPZLSE8++aRsNpvWrVtnrTt79qwKCws1ZcoUTZw4UTk5Oers7Azarr29XcuXL9c111yjlJQUbdiwQefOnQt3uQAAwABhDTBNTU167rnn9I1vfCNo/QMPPKDf//73eumll3To0CGdPn1a3/nOd6z28+fPa/ny5RoYGNBbb72l559/Xnv27NHmzZvDWS4AADBE2AJMb2+v8vLy9Mtf/lKTJ0+21vt8Pv3qV7/SM888o29961uaM2eOdu/erbfeektvv/22JOm1117Te++9p9/85je65ZZbtHTpUv3sZz9TZWWlBgYGwlUyAAAwRNjmwBQWFmr58uXKysrSY489Zq1vbm7W4OCgsrKyrHU33nij0tLS1NDQoNtuu00NDQ2aNWuWnE6n1Sc7O1tr1qxRa2urbr311kv219/fr/7+fuu13+8P05EBuNoxjweIvLAEmBdeeEFHjx5VU1PTJW1er1dxcXFKSkoKWu90OuX1eq0+fx1eLrRfaBtOWVmZtmzZEoLqAQDAWBfyS0gdHR3613/9V+3du1cJCQmhfvvPVVpaKp/PZy0dHR2jtm8AADC6Qh5gmpub1dXVpW9+85uKjY1VbGysDh06pIqKCsXGxsrpdGpgYEA9PT1B23V2dsrlckmSXC7XJXclXXh9oc/F4uPjZbfbgxYAABCdQh5gFi1apHfeeUctLS3WMnfuXOXl5Vl/Hj9+vOrq6qxt2tra1N7eLo/HI0nyeDx655131NXVZfWpra2V3W5XRkZGqEsGAACGCfkcmEmTJunmm28OWjdhwgRNmTLFWl9QUKDi4mIlJyfLbrdr7dq18ng8uu222yRJixcvVkZGhu677z6Vl5fL6/Xqpz/9qQoLCxUfHx/qkgEAgGEi8iTeZ599VjExMcrJyVF/f7+ys7P1i1/8wmofN26cqqurtWbNGnk8Hk2YMEH5+fl69NFHI1EuAFw2fkYBCC9bIBAIRLqIcPD7/XI4HPL5fCGfD8MHEzA8bi/+YnxOAF9upN/f/Bo1AAAwDgEGAAAYh1+jBoBRcvElNi4pAVeOERgAAGAcAgwAADAOAQYAABiHAAMAAIxDgAEAAMYhwAAAAOMQYAAAgHF4DgwARAg/SwJcOQIMgBHhIWwAxhICDIBL8KOMAMY65sAAAADjEGAAAIBxCDAAAMA4BBgAAGAcJvECuCJM9AUQSYzAAAAA4xBgAACAcQgwAADAOMyBAcB8FgDGYQQGAAAYhwADAACMQ4ABAADGIcAAAADjEGAAAIBxCDAAAMA4BBgAAGAcAgwAADAOAQYAABiHJ/ECwBhy8VORP3xyeYQqAcY2RmAAAIBxGIEBohz/owcQjQgwADCGDfdDm4RQgEtIAADAQAQYAABgHC4hAVeZ4S5JwCzMawIIMIDR+CIDcLUK+SWksrIyzZs3T5MmTVJKSopWrlyptra2oD5nz55VYWGhpkyZookTJyonJ0ednZ1Bfdrb27V8+XJdc801SklJ0YYNG3Tu3LlQlwsAAAwU8hGYQ4cOqbCwUPPmzdO5c+f04x//WIsXL9Z7772nCRMmSJIeeOABvfzyy3rppZfkcDhUVFSk73znO3rzzTclSefPn9fy5cvlcrn01ltv6f/+7/90//33a/z48XriiSdCXTIwJjG6AgCfzxYIBALh3MGZM2eUkpKiQ4cOacGCBfL5fLr22mu1b98+ffe735UknThxQjNnzlRDQ4Nuu+02vfLKK/r2t7+t06dPy+l0SpKqqqq0ceNGnTlzRnFxcV+6X7/fL4fDIZ/PJ7vdHtJj4rZGjAbmqmCk+PxBNBnp93fY70Ly+XySpOTkZElSc3OzBgcHlZWVZfW58cYblZaWpoaGBklSQ0ODZs2aZYUXScrOzpbf71dra+uw++nv75ff7w9aAABAdArrJN6hoSGtW7dOd9xxh26++WZJktfrVVxcnJKSkoL6Op1Oeb1eq89fh5cL7RfahlNWVqYtW7aE+AiA0cFoCwBcnrCOwBQWFurdd9/VCy+8EM7dSJJKS0vl8/mspaOjI+z7BAAAkRG2EZiioiJVV1ervr5e1113nbXe5XJpYGBAPT09QaMwnZ2dcrlcVp/Dhw8Hvd+Fu5Qu9LlYfHy84uPjQ3wUAABgLAp5gAkEAlq7dq3279+vN954Q+np6UHtc+bM0fjx41VXV6ecnBxJUltbm9rb2+XxeCRJHo9Hjz/+uLq6upSSkiJJqq2tld1uV0ZGRqhLBkYdl4wA4KsJeYApLCzUvn379Nvf/laTJk2y5qw4HA4lJibK4XCooKBAxcXFSk5Olt1u19q1a+XxeHTbbbdJkhYvXqyMjAzdd999Ki8vl9fr1U9/+lMVFhYyygIAAEIfYHbu3ClJuvvuu4PW7969W9///vclSc8++6xiYmKUk5Oj/v5+ZWdn6xe/+IXVd9y4caqurtaaNWvk8Xg0YcIE5efn69FHHw11uQAAwEBhuYT0ZRISElRZWanKysrP7TN9+nT953/+ZyhLAwAAUYJfowYAAMbhxxxhvJE8cj9cj+XnqcwAEBkEGOAycPcQAIwNBBjg/wtVOOFHGDEWMDqIaEeAAcKMURsACD0CDKIOgQFXG/7O42pEgMFViQ98XI24vIloQoDBmMYHLgBgOAQYjBmMigAARooH2QEAAOMwAoMvdKW3Yl7Jw+UAABgpAgyCjPVQMdbrA0zCs2JgMgLMVYIPKgBANCHAYFQwcgIACCUCDL4ywgkAYLQRYAwUqgmyVxo8CCwAgEjjNmoAAGAcAgwAADAOAQYAABiHAAMAAIzDJF4AgIUfUIUpCDBjzJV8eHBXEADgasMlJAAAYBwCDAAAMA6XkAAAn4vfUcNYRYAZ45jfAgDApbiEBAAAjMMITAQxugLARNxqjbGAERgAAGAcRmAAAF8JE30RCYzAAAAA4zACAwAIOebJINwYgQEAAMZhBGYUcdcRAAChQYABAITdSP4Dx2UmXA4CDABgTOBuJlwO5sAAAADjMAIDABizuJsJn4cRGAAAYJwxPQJTWVmprVu3yuv1avbs2dqxY4fmz58f6bJGhDuOACD0mCeDC8ZsgHnxxRdVXFysqqoqZWZmatu2bcrOzlZbW5tSUlIiXd4lCCwAEBlX8vlL6DHfmA0wzzzzjFatWqUf/OAHkqSqqiq9/PLL+vWvf62SkpIIVwcAiDYjmW/DnJyxY0wGmIGBATU3N6u0tNRaFxMTo6ysLDU0NAy7TX9/v/r7+63XPp9PkuT3+0Ne31D/ZyF/TwDA6El74KWQ9BnJd8zND796ybp3t2R/6XZXqwvnNBAIfGG/MRlg/vznP+v8+fNyOp1B651Op06cODHsNmVlZdqyZcsl61NTU8NSIwAAjm2ju93V5NNPP5XD4fjc9jEZYK5EaWmpiouLrddDQ0Pq7u7WlClTZLPZwr5/v9+v1NRUdXR0yG63h31/VyvO8+jgPIcf53h0cJ5HRyjPcyAQ0Keffiq32/2F/cZkgJk6darGjRunzs7OoPWdnZ1yuVzDbhMfH6/4+PigdUlJSeEq8XPZ7Xb+kYwCzvPo4DyHH+d4dHCeR0eozvMXjbxcMCafAxMXF6c5c+aorq7OWjc0NKS6ujp5PJ4IVgYAAMaCMTkCI0nFxcXKz8/X3LlzNX/+fG3btk19fX3WXUkAAODqNWYDzN///d/rzJkz2rx5s7xer2655RbV1NRcMrF3rIiPj9fDDz98yWUshBbneXRwnsOPczw6OM+jIxLn2Rb4svuUAAAAxpgxOQcGAADgixBgAACAcQgwAADAOAQYAABgHAJMiH344YcqKChQenq6EhMT9bWvfU0PP/ywBgYGIl1a1Hn88cd1++2365prronIQwujVWVlpa6//nolJCQoMzNThw8fjnRJUaW+vl4rVqyQ2+2WzWbTgQMHIl1SVCorK9O8efM0adIkpaSkaOXKlWpra4t0WVFn586d+sY3vmE9wM7j8eiVV14ZlX0TYELsxIkTGhoa0nPPPafW1lY9++yzqqqq0o9//ONIlxZ1BgYGdM8992jNmjWRLiVqvPjiiyouLtbDDz+so0ePavbs2crOzlZXV1ekS4safX19mj17tiorKyNdSlQ7dOiQCgsL9fbbb6u2tlaDg4NavHix+vr6Il1aVLnuuuv05JNPqrm5WUeOHNG3vvUt/d3f/Z1aW1vDvm9uox4FW7du1c6dO/WnP/0p0qVEpT179mjdunXq6emJdCnGy8zM1Lx58/Tzn/9c0l+egJ2amqq1a9eqpKQkwtVFH5vNpv3792vlypWRLiXqnTlzRikpKTp06JAWLFgQ6XKiWnJysrZu3aqCgoKw7ocRmFHg8/mUnJwc6TKALzQwMKDm5mZlZWVZ62JiYpSVlaWGhoYIVgZ8dT6fT5L4LA6j8+fP64UXXlBfX9+o/OzPmH0Sb7T44IMPtGPHDj399NORLgX4Qn/+8591/vz5S5527XQ6deLEiQhVBXx1Q0NDWrdune644w7dfPPNkS4n6rzzzjvyeDw6e/asJk6cqP379ysjIyPs+2UEZoRKSkpks9m+cLn4Q/7UqVNasmSJ7rnnHq1atSpClZvlSs4zAHyRwsJCvfvuu3rhhRciXUpUmjFjhlpaWtTY2Kg1a9YoPz9f7733Xtj3ywjMCK1fv17f//73v7DP3/zN31h/Pn36tBYuXKjbb79du3btCnN10eNyzzNCZ+rUqRo3bpw6OzuD1nd2dsrlckWoKuCrKSoqUnV1terr63XddddFupyoFBcXp69//euSpDlz5qipqUnbt2/Xc889F9b9EmBG6Nprr9W11147or6nTp3SwoULNWfOHO3evVsxMQx0jdTlnGeEVlxcnObMmaO6ujprUunQ0JDq6upUVFQU2eKAyxQIBLR27Vrt379fb7zxhtLT0yNd0lVjaGhI/f39Yd8PASbETp06pbvvvlvTp0/X008/rTNnzlht/C82tNrb29Xd3a329nadP39eLS0tkqSvf/3rmjhxYmSLM1RxcbHy8/M1d+5czZ8/X9u2bVNfX59+8IMfRLq0qNHb26sPPvjAen3y5Em1tLQoOTlZaWlpEawsuhQWFmrfvn367W9/q0mTJsnr9UqSHA6HEhMTI1xd9CgtLdXSpUuVlpamTz/9VPv27dMbb7yhV199Nfw7DyCkdu/eHZA07ILQys/PH/Y8v/7665EuzWg7duwIpKWlBeLi4gLz588PvP3225EuKaq8/vrrw/69zc/Pj3RpUeXzPod3794d6dKiyg9/+MPA9OnTA3FxcYFrr702sGjRosBrr702KvvmOTAAAMA4TM4AAADGIcAAAADjEGAAAIBxCDAAAMA4BBgAAGAcAgwAADAOAQYAABiHAAMAAIxDgAEAAMYhwAAAAOMQYAAAgHEIMAAAwDj/DxyGzSQiOkxlAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#stampa disribuzione dei valori di fpkm_uq_median\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(dataset['fpkm_uq_median'], bins=100)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensioni dataset di test:`(618, 13)`\n",
      "Dimensioni dataset di validazione:`(683, 13)`\n",
      "Dimensioni dataset di train:`(16717, 13)`\n"
     ]
    }
   ],
   "source": [
    "def sparse_to_array(a):\n",
    "    return a.toarray().flatten()\n",
    "\n",
    "# Applica la funzione sparse_to_array a tutte le matrici sparse nella colonna 'array'\n",
    "dataset['array'] = [sparse_to_array(mat) for mat in dataset['array']]\n",
    "\n",
    "test  = dataset[dataset['chromosome_name']=='chr8']\n",
    "val   = dataset[dataset['chromosome_name']=='chr10']\n",
    "train = dataset[(dataset['chromosome_name']!='chr8') & (dataset['chromosome_name']!='chr10')]\n",
    "\n",
    "\n",
    "print(f\"Dimensioni dataset di test:`{test.shape}`\")\n",
    "print(f\"Dimensioni dataset di validazione:`{val.shape}`\")\n",
    "print(f\"Dimensioni dataset di train:`{train.shape}`\")\n",
    "\n",
    "X_trainpromoter = np.array(list(train['Seq']))\n",
    "y_train = train['fpkm_uq_median'].values\n",
    "\n",
    "X_validationpromoter = np.array(list(val['Seq']))\n",
    "y_validation = val['fpkm_uq_median'].values\n",
    "\n",
    "X_testpromoter = np.array(list(test['Seq']))\n",
    "y_test = test['fpkm_uq_median'].values\n",
    "\n",
    "\n",
    "X_met_train = np.array(list(train['array']))\n",
    "X_met_val = np.array(list(val['array']))\n",
    "X_met_test = np.array(list(test['array']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4]\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(X_trainpromoter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import sparse\n",
    "\n",
    "def desparse(a):\n",
    "    return sparse.csr_array(a)\n",
    "\n",
    "#applica sulla colonna array la funzione desparse\n",
    "df['Metilazione_compressed'] = df['array'].apply(desparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indici delle colonne non uguali:\n",
      "[53, 58, 74, 82, 88, 94, 110, 116, 135, 139, 170, 233, 234, 246, 286, 293, 327, 336, 350, 357, 360, 374, 375, 419, 421, 443, 446, 456, 485, 515, 521, 577, 578, 579, 596, 624, 630, 647, 648, 649, 650, 651, 718, 719, 748, 764, 780, 787, 802, 851, 861, 873, 880, 909, 920, 938, 947, 948, 949, 953, 954, 967, 969, 970, 992, 995, 996, 997, 1002, 1039, 1079, 1093, 1097, 1129, 1154, 1160, 1176, 1178, 1181, 1190, 1213, 1228, 1247, 1267, 1270, 1271, 1291, 1297, 1298, 1299, 1300, 1301, 1305, 1308, 1338, 1345, 1346, 1349, 1351, 1353, 1355, 1363, 1366, 1369, 1412, 1424, 1427, 1429, 1447, 1462, 1463, 1464, 1507, 1521, 1537, 1549, 1586, 1598, 1599, 1600, 1601, 1602, 1620, 1622, 1623, 1631, 1637, 1649, 1659, 1660, 1663, 1683, 1689, 1702, 1725, 1737, 1743, 1752, 1753, 1763, 1774, 1782, 1806, 1816, 1821, 1840, 1867, 1872, 1878, 1890, 1895, 1900, 1902, 1906, 1910, 1912, 1935, 1993, 2015, 2048, 2052, 2062, 2073, 2139, 2182, 2217, 2227, 2288, 2291, 2333, 2344, 2379, 2388, 2433, 2435, 2445, 2484, 2518, 2519, 2520, 2528, 2557, 2569, 2574, 2578, 2617, 2626, 2806, 2885, 2934, 2936, 2937, 2938, 2940, 2974, 2975, 2990, 3003, 3019, 3021, 3022, 3091, 3112, 3136, 3157, 3203, 3245, 3302, 3326, 3331, 3339, 3437, 3446, 3463, 3467, 3471, 3479, 3493, 3511, 3524, 3565, 3645, 3649, 3653, 3681, 3687, 3699, 3713, 3734, 3735, 3738, 3740, 3745, 3750, 3766, 3779, 3798, 3810, 3814, 3815, 3819, 3851, 3907, 3914, 3916, 3956, 3964, 3982, 3984, 3999, 4021, 4038, 4044, 4061, 4068, 4089, 4115, 4269, 4272, 4300, 4305, 4313, 4376, 4396, 4517, 4547, 4564, 4586, 4589, 4590, 4596, 4603, 4607, 4658, 4693, 4703, 4711, 4718, 4774, 4779, 4795, 4806, 4845, 4854, 4883, 4906, 4912, 4931, 4959, 4984, 4995, 5045, 5065, 5119, 5136, 5137, 5158, 5167, 5336, 5337, 5338, 5342, 5343, 5344, 5345, 5346, 5347, 5348, 5349, 5363, 5364, 5365, 5366, 5367, 5368, 5369, 5370, 5371, 5372, 5373, 5374, 5375, 5376, 5377, 5382, 5432, 5487, 5494, 5523, 5536, 5592, 5595, 5599, 5604, 5625, 5637, 5670, 5694, 5696, 5707, 5711, 5713, 5714, 5715, 5725, 5770, 5774, 5779, 5795, 5808, 5820, 5825, 5833, 5866, 5939, 5975, 5980, 6011, 6027, 6031, 6059, 6060, 6061, 6062, 6063, 6065, 6087, 6109, 6149, 6155, 6158, 6161, 6163, 6179, 6235, 6279, 6285, 6304, 6313, 6325, 6328, 6350, 6363, 6386, 6394, 6436, 6470, 6471, 6472, 6473, 6474, 6475, 6501, 6514, 6515, 6517, 6518, 6526, 6544, 6547, 6550, 6561, 6578, 6584, 6591, 6595, 6627, 6639, 6649, 6686, 6690, 6709, 6710, 6722, 6727, 6739, 6746, 6780, 6788, 6791, 6792, 6799, 6832, 6848, 6849, 6854, 6856, 6863, 6867, 6874, 6895, 6902, 6912, 6913, 6928, 6970, 6973, 6996, 6997, 7009, 7011, 7051, 7062, 7069, 7074, 7097, 7120, 7134, 7138, 7147, 7150, 7186, 7187, 7190, 7194, 7200, 7214, 7219, 7240, 7263, 7266, 7270, 7279, 7297, 7457, 7463, 7487, 7506, 7546, 7547, 7556, 7602, 7643, 7676, 7720, 7725, 7799, 7827, 7828, 7834, 7839, 7872, 7878, 7886, 7893, 7904, 7908, 7909, 7928, 7959, 7979, 8024, 8050, 8053, 8059, 8065, 8067, 8138, 8139, 8158, 8215, 8238, 8249, 8251, 8252, 8274, 8278, 8288, 8290, 8291, 8292, 8293, 8323, 8326, 8332, 8353, 8373, 8388, 8401, 8402, 8411, 8435, 8454, 8468, 8481, 8486, 8488, 8489, 8511, 8514, 8523, 8570, 8584, 8593, 8612, 8615, 8616, 8619, 8620, 8626, 8643, 8744, 8824, 8832, 8888, 8924, 8926, 8937, 8939, 8943, 8952, 8953, 8966, 9005, 9084, 9135, 9165, 9168, 9249, 9272, 9345, 9354, 9378, 9391, 9393, 9394, 9395, 9401, 9405, 9414, 9418, 9435, 9445, 9471, 9478, 9482, 9494, 9500, 9510, 9540, 9545, 9550, 9551, 9553, 9554, 9562, 9563, 9565, 9582, 9595, 9596, 9608, 9613, 9618, 9631, 9636, 9656, 9663, 9670, 9672, 9673, 9675, 9713, 9786, 9804, 9825, 9862, 9863, 9915, 9932, 9933, 9938, 9949, 9967, 9992, 10004, 10021, 10030, 10039, 10062, 10064, 10069, 10078, 10079, 10080, 10083, 10088, 10094, 10101, 10102, 10122, 10125, 10126, 10129, 10130, 10152, 10153, 10158, 10175, 10188, 10189, 10195, 10210, 10216, 10228, 10235, 10244, 10247, 10258, 10261, 10290, 10321, 10356, 10373, 10374, 10390, 10391, 10428, 10470, 10479, 10480, 10509, 10519, 10522, 10526, 10528, 10537, 10572, 10590, 10592, 10595, 10600, 10631, 10634, 10641, 10655, 10685, 10691, 10706, 10718, 10719, 10720, 10752, 10754, 10788, 10825, 10830, 10862, 10863, 10878, 10880, 10885, 10894, 10903, 10921, 10933, 10943, 10952, 10958, 10960, 10964, 10967, 10972, 10982, 10983, 10984, 10986, 10987, 10989, 10991, 11026, 11031, 11042, 11044, 11046, 11049, 11055, 11099, 11106, 11109, 11126, 11130, 11140, 11151, 11177, 11186, 11195, 11228, 11280, 11291, 11296, 11302, 11370, 11386, 11423, 11426, 11452, 11454, 11468, 11469, 11491, 11564, 11661, 11677, 11699, 11755, 11765, 11776, 11778, 11786, 11797, 11804, 11806, 11812, 11814, 11824, 11826, 11834, 11844, 11848, 11866, 11867, 11890, 11931, 11935, 11942, 11954, 11969, 12017, 12021, 12022, 12027, 12044, 12049, 12075, 12157, 12163, 12165, 12183, 12188, 12191, 12318, 12334, 12376, 12441, 12503, 12533, 12554, 12692, 12732, 12734, 12787, 12825, 12872, 12874, 12875, 12892, 12896, 12903, 12913, 12914, 12915, 12926, 12939, 12947, 12958, 12970, 12973, 12974, 12979, 12991, 13002, 13024, 13032, 13034, 13041, 13050, 13055, 13058, 13060, 13061, 13073, 13082, 13085, 13089, 13097, 13104, 13105, 13124, 13126, 13127, 13129, 13136, 13155, 13159, 13165, 13170, 13171, 13172, 13173, 13174, 13175, 13179, 13184, 13194, 13202, 13210, 13216, 13222, 13227, 13241, 13246, 13255, 13256, 13258, 13260, 13261, 13262, 13286, 13292, 13300, 13314, 13333, 13334, 13336, 13342, 13353, 13354, 13355, 13360, 13364, 13366, 13368, 13369, 13370, 13371, 13375, 13385, 13387, 13409, 13412, 13418, 13426, 13432, 13434, 13435, 13436, 13444, 13445, 13458, 13459, 13461, 13465, 13470, 13475, 13486, 13494, 13503, 13504, 13506, 13516, 13523, 13536, 13539, 13543, 13552, 13560, 13561, 13563, 13565, 13568, 13577, 13579, 13581, 13589, 13590, 13599, 13611, 13616, 13619, 13623, 13630, 13631, 13639, 13643, 13654, 13663, 13669, 13671, 13687, 13699, 13703, 13709, 13720, 13722, 13741, 13743, 13765, 13793, 13808, 13814, 13828, 13829, 13831, 13842, 13853, 13854, 13855, 13856, 13857, 13869, 13870, 13872, 13873, 13874, 13875, 13876, 13878, 13879, 13880, 13897, 13905, 13915, 13940, 13949, 13960, 13970, 14011, 14019, 14032, 14035, 14042, 14048, 14055, 14073, 14104, 14106, 14112, 14129, 14130, 14135, 14138, 14144, 14147, 14161, 14163, 14164, 14171, 14175, 14197, 14219, 14224, 14225, 14227, 14232, 14247, 14253, 14265, 14285, 14296, 14308, 14313, 14323, 14325, 14329, 14344, 14348, 14355, 14360, 14361, 14362, 14365, 14366, 14374, 14386, 14389, 14406, 14432, 14435, 14444, 14476, 14512, 14525, 14538, 14539, 14565, 14573, 14585, 14586, 14594, 14595, 14752, 14769, 14833, 14834, 14864, 14867, 14877, 14883, 14885, 14903, 14910, 14911, 14916, 14923, 14930, 14932, 14934, 14951, 14953, 14969, 14974, 14975, 14981, 14988, 15006, 15008, 15009, 15027, 15032, 15041, 15067, 15079, 15080, 15086, 15092, 15093, 15107, 15118, 15127, 15128, 15131, 15142, 15156, 15157, 15158, 15165, 15167, 15169, 15170, 15173, 15180, 15187, 15193, 15199, 15206, 15209, 15213, 15214, 15216, 15217, 15220, 15221, 15229, 15250, 15265, 15268, 15269, 15271, 15276, 15285, 15304, 15307, 15310, 15318, 15331, 15332, 15352, 15354, 15356, 15365, 15366, 15367, 15369, 15375, 15379, 15382, 15389, 15392, 15396, 15400, 15401, 15405, 15407, 15433, 15434, 15435, 15437, 15442, 15458, 15467, 15468, 15472, 15473, 15474, 15478, 15490, 15493, 15511, 15514, 15518, 15519, 15520, 15527, 15532, 15533, 15536, 15539, 15554, 15555, 15556, 15559, 15573, 15574, 15587, 15596, 15600, 15606, 15607, 15610, 15612, 15614, 15616, 15618, 15629, 15635, 15637, 15643, 15644, 15665, 15666, 15680, 15684, 15685, 15687, 15693, 15715, 15716, 15719, 15745, 15749, 15758, 15759, 15760, 15761, 15767, 15768, 15774, 15777, 15778, 15779, 15780, 15792, 15800, 15807, 15815, 15822, 15843, 15846, 15861, 15862, 15863, 15877, 15902, 15905, 15915, 15921, 15923, 15928, 15929, 15931, 15933, 15934, 15939, 15941, 15942, 15944, 15971, 15972, 15974, 15975, 15981, 15982, 15986, 15994, 15998, 15999, 16002, 16004, 16005, 16016, 16017, 16018, 16021, 16023, 16024, 16026, 16033, 16034, 16041, 16042, 16044, 16046, 16054, 16057, 16062, 16063, 16064, 16065, 16069, 16070, 16071, 16073, 16079, 16080, 16082, 16086, 16089, 16093, 16096, 16105, 16108, 16111, 16115, 16124, 16126, 16127, 16141, 16142, 16143, 16144, 16145, 16146, 16148, 16149, 16152, 16154, 16156, 16159, 16160, 16161, 16167, 16171, 16173, 16226, 16231, 16232, 16249, 16253, 16265, 16277, 16287, 16303, 16309, 16310, 16332, 16335, 16353, 16404, 16414, 16422, 16446, 16448, 16453, 16455, 16476, 16480, 16489, 16490, 16493, 16497, 16502, 16513, 16521, 16539, 16541, 16548, 16558, 16561, 16567, 16590, 16615, 16618, 16638, 16641, 16647, 16651, 16659, 16662, 16673, 16696, 16698, 16701, 16702, 16703, 16706, 16707, 16708, 16718, 16719, 16726, 16734, 16761, 16762, 16763, 16764, 16765, 16766, 16771, 16772, 16776, 16778, 16781, 16797, 16802, 16805, 16815, 16816, 16817, 16818, 16822, 16858, 16861, 16863, 16865, 16868, 16870, 16871, 16873, 16882, 16895, 16901, 16902, 16907, 16924, 16931, 16945, 16946, 16975, 16982, 16987, 16993, 17002, 17007, 17013, 17018, 17022, 17026, 17053, 17071, 17077, 17081, 17101, 17103, 17110, 17120, 17124, 17129, 17138, 17139, 17143, 17152, 17160, 17174, 17179, 17182, 17192, 17204, 17210, 17216, 17217, 17222, 17249, 17257, 17261, 17262, 17263, 17264, 17266, 17267, 17271, 17272, 17320, 17323, 17368, 17376, 17398, 17429, 17474, 17479, 17515, 17522, 17523, 17525, 17540, 17541, 17554, 17559, 17561, 17564, 17580, 17594, 17598, 17601, 17608, 17622, 17652, 17656, 17661, 17667, 17702, 17737, 17742, 17763, 17766, 17771, 17772, 17773, 17798, 17836, 17875, 17880, 17882, 17910, 17932, 17960, 17972, 17976, 17981, 17985, 17986, 17990, 18002, 18007, 18017]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "def check_equality(original_column, compressed_column, column_index):\n",
    "    # Converte la colonna compressa in un array NumPy\n",
    "    compressed_array = compressed_column.toarray()\n",
    "\n",
    "    # Verifica l'uguaglianza degli array\n",
    "    if not (original_column == compressed_array).all():\n",
    "        return column_index\n",
    "\n",
    "\n",
    "# Controlla l'uguaglianza per ogni riga\n",
    "indices_non_uguali = []\n",
    "for index, row in df.iterrows():\n",
    "    original_column = row['array']\n",
    "    compressed_column = row['Metilazione_compressed']\n",
    "    non_uguali = check_equality(original_column, compressed_column, index)\n",
    "    if non_uguali is not None:\n",
    "        indices_non_uguali.append(non_uguali)\n",
    "\n",
    "# Stampa gli indici delle colonne non uguali\n",
    "if indices_non_uguali:\n",
    "    print(\"Indici delle righe non uguali:\")\n",
    "    print(indices_non_uguali)\n",
    "else:\n",
    "    print(\"Tutte le righe sono uguali.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 1])\n",
      "torch.Size([32, 1, 128])\n",
      "torch.Size([32, 1, 129])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "\n",
    "# Supponendo che metsum e pooled_output siano i tuoi tensori\n",
    "metsum = torch.randn(32)\n",
    "pooled_output = torch.randn(32, 1, 128)\n",
    "\n",
    "# Aggiungi una dimensione al tensore metsum per renderlo compatibile con pooled_output\n",
    "metsum_expanded = metsum.unsqueeze(1).unsqueeze(-1)\n",
    "print(metsum_expanded.shape)  # Stampa la forma del tensore espanso\n",
    "print(pooled_output.shape)  # Stampa la forma di pooled_output\n",
    "# Concatena i due tensori lungo l'ultima dimensione\n",
    "concatenated_tensor = torch.cat((pooled_output, metsum_expanded), dim=-1)\n",
    "\n",
    "print(concatenated_tensor.shape)  # Stampa la forma del tensore concatenato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lunghezza_dataset = len(dataset)\n",
    "# Calcola il numero di esempi per 'train', 'val' e 'test' rispettivamente\n",
    "num_train = int(lunghezza_dataset * 0.85)\n",
    "num_val = int(lunghezza_dataset * 0.1)\n",
    "num_test = lunghezza_dataset - num_train - num_val\n",
    "# Crea un array che rappresenta la suddivisione in 'train', 'val' e 'test'\n",
    "suddivisione = ['train'] * num_train + ['val'] * num_val + ['test'] * num_test\n",
    "# Permischi l'array per garantire che le istanze siano distribuite casualmente\n",
    "np.random.shuffle(suddivisione)\n",
    "# Aggiungi la colonna 'split' al DataFrame\n",
    "dataset['split'] = suddivisione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Danilo\\anaconda3\\envs\\AIE\\Lib\\site-packages\\tables\\path.py:137: NaturalNameWarning: object name is not a valid Python identifier: '1234'; it does not match the pattern ``^[a-zA-Z_][a-zA-Z0-9_]*$``; you will not be able to use natural naming to access this object; using ``getattr()`` will still work, though\n",
      "  check_attribute_name(name)\n",
      "C:\\Users\\Danilo\\AppData\\Local\\Temp\\ipykernel_12784\\282318420.py:11: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block2_values] [items->Index(['gene_id', 'gene_type', 'split', 'gene_name', 'chromosome_name',\n",
      "       'strand', 'Seq', 'array'],\n",
      "      dtype='object')]\n",
      "\n",
      "  chunk.to_hdf(f'../dataset/Dataset/df_alBERTo_{i}.h5',key='1234', mode='w')\n"
     ]
    }
   ],
   "source": [
    "#salva il dataset dividendolo in 5 parti\n",
    "dataset = dataset.reset_index(drop=True)\n",
    "dataset_size = len(dataset)\n",
    "chunk_size = dataset_size // 5\n",
    "for i in range(5):\n",
    "    start = i * chunk_size\n",
    "    end = (i + 1) * chunk_size\n",
    "    if i == 4:\n",
    "        end = dataset_size\n",
    "    chunk = dataset.iloc[start:end]\n",
    "    chunk.to_hdf(f'../dataset/Dataset/df_alBERTo_{i}.h5',key='1234', mode='w')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#controlla se la colonna 'StringSeq' Ã¨ stata creata correttamente confrontandola con la colonna 'Seq'\n",
    "for index, row in dataset.iterrows():\n",
    "    if not (row['Seq'] == row['StringSeq'].toarray()).all():\n",
    "        print(f\"Errore alla riga {index}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# elimina la colonna 'Seq' e rinomina la colonna 'StringSeq' in 'Seq'\n",
    "dataset = dataset.drop(columns=['Seq'])\n",
    "dataset = dataset.rename(columns={'StringSeq': 'Seq'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Supponiamo che 'dataset' sia il tuo DataFrame da salvare\n",
    "\n",
    "#converti array in list\n",
    "dataset['array'] = [a.toarray().tolist() for a in dataset['array']]\n",
    "\n",
    "# Definisci il numero di chunk\n",
    "num_chunks = 4\n",
    "\n",
    "# Calcola la dimensione del chunk\n",
    "chunk_size = len(dataset) // num_chunks\n",
    "\n",
    "# Crea un nuovo file HDF5\n",
    "with pd.HDFStore('../dataset/Dataset/alberto_seq_array.h5', mode='w') as store:\n",
    "    # Salva il dataset in chunk\n",
    "    for i in range(num_chunks):\n",
    "        start_idx = i * chunk_size\n",
    "        end_idx = start_idx + chunk_size if i < num_chunks - 1 else None\n",
    "        chunk = dataset.iloc[start_idx:end_idx]\n",
    "        \n",
    "        # Salva il chunk nel file HDF5 come un gruppo\n",
    "        store.put(f'chunk_{i}', chunk, format='table', data_columns=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AIE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
